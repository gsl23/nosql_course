Устанавливал из пакетов, RedHat 3 сервера 
test-host1
test-host2
test-host3

по портам: 27017-shards, 27019-config-servers, 27018 query-router


--------- Install MongoDB cluster (3 nodes, repl+sharding ) ---------

1. Install MongoDB on All Instances
Check: 
mongod --version
db version v4.4.14
Build Info: {
    "version": "4.4.14",
....

2. Add Replication and init authentification : 

2.1 Generate key and copy it on all nodes :
 openssl rand -base64 756 > /data/mongo-keyfile
 chown mongod:mongod /data/mgdb/mongo-keyfile
 chmod 400 /data/mongo-keyfile
 
2.2 Create user 
> use admin
switched to db admin
> db.createUser({user: "mongo-admin", pwd: "password", roles:[{role: "root", db: "admin"}]})

2.3 Change config on all nodes :  
vi /etc/mongod.conf : 

security:
  authorization: 'enabled' # 'enabled'
  keyFile: /data/mgdb/mongo-keyfile
....
replication:
  replSetName: "rs01"


3. Init replication : 

> rs.initiate(
{"_id" : "rs01", members : 
[{"_id" : 0, host : "test-host1:27017"},
 {"_id" : 1, host : "test-host2:27017"},
 {"_id" : 2, host : "test-host3:27017"}]
 }
);
{ "ok" : 1 }

4. Add config server (for sharding cluster )
create new conf and service on every host :
------------
net:
  bindIp: '0.0.0.0'
  ipv6: false
  maxIncomingConnections: 65536
  port: 27019

processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongod-cs.pid

security:
  authorization: 'enabled'
  keyFile: /data/mgdb/mongo-keyfile
  
storage:
  dbPath: /data/mgdb/csdb
  directoryPerDB: false
  engine: wiredTiger
  journal:
    enabled: true
  wiredTiger:
    engineConfig:
      directoryForIndexes: false

systemLog:
  destination: file
  logAppend: true
  logRotate: rename
  path: /var/log/mongodb/mongod-cs.log

replication:
  replSetName: "rs-cs"
sharding:
  clusterRole: configsvr
------------

and create data dir for config db : 
mkdir /data/mgdb/csdb
chown mongod:mongod  /data/mgdb/csdb

4. Init configsvr cluster 
rs.initiate(
  {
    _id: "rs-cs",
    configsvr: true,
    members: [
      { _id : 0, host : "test-host1:27019" },
      { _id : 1, host : "test-host2:27019" },
	  { _id : 2, host : "test-host3:27019" },
    ]
  }
)

rs-cs:PRIMARY> rs.status()
{
        "set" : "rs-cs",
        "date" : ISODate("2022-07-01T18:22:43.682Z"),
        "myState" : 1,
        "term" : NumberLong(1),
        "syncSourceHost" : "",
        "syncSourceId" : -1,
        "configsvr" : true,
....

5. Add shard config to data nodes  /etc/mongod.conf :

sharding:
  clusterRole: shardsvr

restart 

6. Init query router 

6.1 Create config /etc/mongos.conf :
------------
net:
  bindIp: '0.0.0.0'
  ipv6: false
  maxIncomingConnections: 65536
  port: 27018

processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongos.pid

security:
  keyFile: /data/mgdb/mongo-keyfile

systemLog:
  destination: file
  logAppend: true
  logRotate: rename
  path: /var/log/mongodb/mongos.log

sharding:
  configDB: rs-cs/test-host1:27019,test-host2:27019,test-host3:27019
------------

6.2 Create systemd init :
------------
# /usr/lib/systemd/system/mongos.service
[Unit]
Description=Mongo Cluster Router
Documentation=https://docs.mongodb.org/manual
After=network-online.target
Wants=network-online.target

[Service]
User=mongod
Group=mongod
Environment="OPTIONS=-f /etc/mongos.conf"
EnvironmentFile=-/etc/sysconfig/mongos
ExecStart=/usr/bin/mongos $OPTIONS
ExecStartPre=/usr/bin/mkdir -p /var/run/mongodb
ExecStartPre=/usr/bin/chown mongod:mongod /var/run/mongodb
ExecStartPre=/usr/bin/chmod 0755 /var/run/mongodb
PermissionsStartOnly=true
PIDFile=/var/run/mongodb/mongos.pid
Type=forking
# file size
LimitFSIZE=infinity
# cpu time
LimitCPU=infinity
# virtual memory size
LimitAS=infinity
# open files
LimitNOFILE=64000
# processes/threads
LimitNPROC=64000
# locked memory
LimitMEMLOCK=infinity
# total threads (user+kernel)
TasksMax=infinity
TasksAccounting=false

[Install]
WantedBy=multi-user.target
------------

systemctl start mongos 


7. Add shards 
Connect to query router : 
mongo --port 27018 -u admin
> sh.addShard( "rs01/test-host1:27017")
> sh.addShard( "rs01/test-host2:27017")
> sh.addShard( "rs01/test-host3:27017")

Check : 
> sh.status()
--- Sharding Status ---
  sharding version: {
        "_id" : 1,
        "minCompatibleVersion" : 5,
        "currentVersion" : 6,
        "clusterId" : ObjectId("62bf3b2b5116a6352c1a3cb5")
  }
  shards:
        {  "_id" : "rs01",  "host" : "rs01/test-host1:27017,test-host2:27017,test-host3:27017",  "state" : 1 }
  active mongoses:
        "4.4.14" : 1
  autosplit:
        Currently enabled: yes
  balancer:
        Currently enabled:  yes
        Currently running:  no
        Failed balancer rounds in last 5 attempts:  0
        Migration Results for the last 24 hours:
                No recent migrations
  databases:
        {  "_id" : "config",  "primary" : "config",  "partitioned" : true }
        {  "_id" : "test",  "primary" : "rs01",  "partitioned" : false,  "version" : {  "uuid" : UUID("06592881-9e66-4dbe-b616-75b18ba7693c"),  "lastMod" : 1 } }
        {  "_id" : "uber",  "primary" : "rs01",  "partitioned" : false,  "version" : {  "uuid" : UUID("998e9d00-5b1b-4b35-afb0-00fe10f8da77"),  "lastMod" : 1 } }


8. Let's try to shard existing collection 
> sh.enableSharding("uber")

> use uber
switched to db uber
> show collections
dummy
rawdata
> db.rawdata.find().limit(5)
{ "_id" : ObjectId("628d2f64ba98ae5016a970f1"), "Dispatching_base_num" : "B02617", "Pickup_date" : ISODate("2015-05-17T09:47:00Z"), "Affiliated_base_num" : "B02617", "locationID" : 141 }
{ "_id" : ObjectId("628d2f64ba98ae5016a970f2"), "Dispatching_base_num" : "B02617", "Pickup_date" : ISODate("2015-05-17T09:47:00Z"), "Affiliated_base_num" : "B02617", "locationID" : 65 }
{ "_id" : ObjectId("628d2f64ba98ae5016a970f3"), "Dispatching_base_num" : "B02617", "Pickup_date" : ISODate("2015-05-17T09:47:00Z"), "Affiliated_base_num" : "B02617", "locationID" : 100 }
{ "_id" : ObjectId("628d2f64ba98ae5016a970f4"), "Dispatching_base_num" : "B02617", "Pickup_date" : ISODate("2015-05-17T09:47:00Z"), "Affiliated_base_num" : "B02774", "locationID" : 80 }
{ "_id" : ObjectId("628d2f64ba98ae5016a970f5"), "Dispatching_base_num" : "B02617", "Pickup_date" : ISODate("2015-05-17T09:47:00Z"), "Affiliated_base_num" : "B02617", "locationID" : 90 }

> db.rawdata.getIndexes()
[
        {
                "v" : 2,
                "key" : {
                        "Pickup_date" : 1
                },
                "name" : "Pickup_date_1"
        },
        {
                "v" : 2,
                "key" : {
                        "locationID" : 1
                },
                "name" : "locationID_1"
        },
        {
                "v" : 2,
                "key" : {
                        "_id" : 1
                },
                "name" : "_id_"
        }
]

8.1 Add sharding by locationID field. 
> sh.shardCollection(
  "uber.rawdata",
  { locationID: "hashed" },
  false )
  
 We got error : 
 {
        "ok" : 0,
        "errmsg" : "Please create an index that starts with the proposed shard key before sharding the collection",
Problem is we have ordinnary non-hashed index on "locationID". Recreate It:
> db.rawdata.dropIndex("locationID_1")
> db.rawdata.createIndex({"locationID":"hashed"})

and retry shard collection.
Check : 
> db.rawdata.getShardDistribution()

Shard rs01 at rs01/test-host1:27017,test-host2:27017,test-host3:27017
 data : 1.64GiB docs : 14270479 chunks : 26
 estimated data per chunk : 64.87MiB
 estimated docs per chunk : 548864

Totals
 data : 1.64GiB docs : 14270479 chunks : 26
 Shard rs01 contains 100% data, 100% docs in cluster, avg obj size on shard : 123B

9. Tests.
9.1 Use script from previous homework.
# cat script.txt
use uber
db.rawdata.count({ "locationID" : 141, "Pickup_date":{$gte : ISODate("2015-06-01"),$lte : ISODate("2015-07-01")} } )

time mongo --port 27018 -u admin -p **** < /tmp/script.txt
MongoDB shell version v4.4.14
connecting to: mongodb://127.0.0.1:27018/?compressors=disabled&gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("98d0e077-91c7-4384-8ac9-871c4c8ca6d9") }
MongoDB server version: 4.4.14
switched to db uber
37241
bye

real    0m0.725s
user    0m0.094s
sys     0m0.034s

9.2 Shut one shard and config node and run test again: 
# systemctl stop mongod
# systemctl stop mongod-cs

# time mongo --port 27018 -u admin -p *** < /tmp/script.txt
connecting to: mongodb://127.0.0.1:27018/?compressors=disabled&gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("b081c07c-be9c-44ac-850b-3e639f77c14b") }
MongoDB server version: 4.4.14
switched to db uber
37241
bye

real    0m0.681s
user    0m0.106s
sys     0m0.029s

9.3 Shut second shard and config node 
on another cluster host 
# systemctl stop mongod
# systemctl stop mongod-cs
and re-test : 
# time mongo --port 27018 -u admin -p *** < /tmp/script.txt
MongoDB shell version v4.4.14
connecting to: mongodb://127.0.0.1:27018/?compressors=disabled&gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("bb2d2563-ca53-484c-8b9e-c21a5e0c8a14") }
MongoDB server version: 4.4.14
switched to db uber
uncaught exception: Error: count failed: {
        "ok" : 0,
        "errmsg" : "failed on: rs01 :: caused by :: Could not find host matching read preference { mode: \"primary\" } for set rs01",
9.4 Start one shard node but not config and re-test :
 time mongo --port 27018 -u admin -p *** < /tmp/script.txt
MongoDB shell version v4.4.14
connecting to: mongodb://127.0.0.1:27018/?compressors=disabled&gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("ace0380e-0e20-4b41-a98d-b3ab9d82dbc0") }
MongoDB server version: 4.4.14
switched to db uber
37241
bye

real    0m3.036s
user    0m0.095s
sys     0m0.031s


Interesting, but in working only with one config node. 
Connect to cs db and check: 
> rs.status()
{
        "set" : "rs-cs",
        "date" : ISODate("2022-07-03T13:04:46.462Z"),
        "myState" : 2,
        "term" : NumberLong(3),
        "syncSourceHost" : "",
        "syncSourceId" : -1,
        "configsvr" : true,
...		
                        "name" : "test-host1:27019",
                        "health" : 0,
                        "state" : 8,
                        "stateStr" : "(not reachable/healthy)",
...
                        "name" : "test-host2:27019",
                        "health" : 0,
                        "state" : 8,
                        "stateStr" : "(not reachable/healthy)",
...
                        "name" : "test-host3:27019",
                        "health" : 1,
                        "state" : 2,
                        "stateStr" : "SECONDARY",
...
